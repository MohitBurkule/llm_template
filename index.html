<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Riddle AI with WebLLM</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      font-family: 'Arial', sans-serif;
      background-color: #2b2b2b;
      color: #f4f4f4;
      margin: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 10px;
    }
    h1, p {
      text-align: center;
    }
    .download-container, .riddle-container {
      margin: 20px 0;
    }
    .hidden {
      display: none;
    }
    .chat-box {
      background-color: #3e3e3e;
      width: 90%;
      max-width: 600px;
      height: 150px;
      border-radius: 10px;
      overflow-y: auto;
      padding: 10px;
      margin: 10px 0;
    }
    .chat-stats {
      background-color: #4c4c4c;
      padding: 10px;
      margin-top: 10px;
      border-radius: 5px;
    }
    .chat-input-container {
      display: flex;
      justify-content: center;
      align-items: center;
      gap: 10px;
      margin-top: 10px;
    }
    .message-container {
      margin: 5px 0;
      padding: 8px;
      border-radius: 5px;
    }
    .assistant {
      background-color: #444;
      text-align: left;
    }
    .user {
      background-color: #2f2f2f;
      text-align: right;
    }
    .message {
      white-space: pre-wrap;
      word-wrap: break-word;
    }
  </style>
</head>
<body>
<h1>Riddle AI with WebLLM</h1>

<!-- Step 1: Model Initialization -->
<p>Select a model and download it before answering the riddle:</p>
<div class="download-container">
  <select id="model-selection"></select>
  <button id="download">Download</button>
  <p id="download-status" class="hidden"></p>
</div>

<!-- Step 2: Riddle Game -->
<div class="riddle-container">
  <p><strong>Riddle:</strong> I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?</p>
  <div class="chat-container">
    <div id="chat-box" class="chat-box"></div>
    <div id="chat-stats" class="chat-stats hidden"></div>
    <div class="chat-input-container">
      <label for="user-input">My guess is: </label>
      <input type="text" id="user-input" placeholder="Enter your guess..." />
      <button id="send" disabled>Submit</button>
    </div>
  </div>
</div>

<script type="module">
  import * as webllm from "https://esm.run/@mlc-ai/web-llm";

  // Revised system prompt:
  // All user submissions will be prefixed with "my guess is ".
  // The AI must remove that prefix, compare case-insensitively to "echo",
  // and if it matches exactly, reply with "Correct!".
  // If not, reply with a brief hint without revealing the answer.
  const messages = [
    {
      role: "system",
      content: "You are a riddle answer checking AI. The riddle is: 'I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?' The correct answer is 'echo'. When a player submits a guess compare the guess case-insensitively to 'echo'. If the guess is exactly 'echo', reply with 'Correct!' . Otherwise, reply only with a brief hint related to the riddle without revealing the answer or adding extra commentary.Never reveal the answer first"
    }
  ];

  // Filter models: only include those with "q4f32" and "SmolLM2".
  const availableModels = webllm.prebuiltAppConfig.model_list
          .filter(m => m.model_id.includes("q4f32"))
          // .filter(m => m.model_id.includes("SmolLM2"))
          .map(m => m.model_id);
  let selectedModel = availableModels[0] || "SmolLM2-360M-Instruct-q4f32_1-MLC";

  const engine = new webllm.MLCEngine();

  function updateEngineInitProgressCallback(report) {
    console.log("initialize", report.progress);
    document.getElementById("download-status").textContent = report.text;
  }
  engine.setInitProgressCallback(updateEngineInitProgressCallback);

  async function initializeWebLLMEngine() {
    document.getElementById("download-status").classList.remove("hidden");
    selectedModel = document.getElementById("model-selection").value;
    const config = {
      temperature: 0.2, // Lower temperature for deterministic output.
      top_p: 1,
    };
    await engine.reload(selectedModel, config);
  }

  async function streamingGenerating(messages, onUpdate, onFinish, onError) {
    console.log(messages);
    try {
      let curMessage = "";
      const completion = await engine.chat.completions.create({
        stream: true,
        messages,
      });
      for await (const chunk of completion) {
        const curDelta = chunk.choices[0]?.delta?.content;
        if (curDelta) {
          curMessage += curDelta;
        }
        onUpdate(curMessage);
      }
      const finalMessage = await engine.getMessage();
      onFinish(finalMessage);
    } catch (err) {
      onError(err);
    }
  }

  function onMessageSend() {
    const input = document.getElementById("user-input").value.trim();
    if (input.length === 0) return;

    document.getElementById("send").disabled = true;

    // Prepend "my guess is " to the user's submission.
    const userContent = "my guess is " + input;
    const userMessage = { role: "user", content: userContent };
    messages.push(userMessage);
    appendMessage(userMessage);

    document.getElementById("user-input").value = "";
    document.getElementById("user-input").setAttribute("placeholder", "Checking your guess...");

    // Display a temporary "thinking..." message only in the UI.
    const tempElement = { role: "assistant", content: "thinking..." };
    appendMessage(tempElement);

    // Do not add the temporary message to the conversation array.
    streamingGenerating(
            messages,
            (partialResponse) => {
              updateLastMessage(partialResponse);
            },
            (finalMessage) => {
              updateLastMessage(finalMessage);
              messages.push({ role: "assistant", content: finalMessage });
              document.getElementById("send").disabled = false;
              document.getElementById("user-input").setAttribute("placeholder", "Enter your guess...");
              engine.runtimeStatsText().then((statsText) => {
                document.getElementById("chat-stats").classList.remove("hidden");
                document.getElementById("chat-stats").textContent = statsText;
              });
            },
            console.error
    );
  }

  function appendMessage(message) {
    const chatBox = document.getElementById("chat-box");
    const container = document.createElement("div");
    container.classList.add("message-container");
    const newMessage = document.createElement("div");
    newMessage.classList.add("message");
    newMessage.textContent = message.content;

    if (message.role === "user") {
      container.classList.add("user");
    } else {
      container.classList.add("assistant");
    }
    container.appendChild(newMessage);
    chatBox.appendChild(container);
    chatBox.scrollTop = chatBox.scrollHeight;
  }

  function updateLastMessage(content) {
    const messageDoms = document.getElementById("chat-box").querySelectorAll(".message");
    const lastMessageDom = messageDoms[messageDoms.length - 1];
    lastMessageDom.textContent = content;
  }

  availableModels.forEach((modelId) => {
    const option = document.createElement("option");
    option.value = modelId;
    option.textContent = modelId;
    document.getElementById("model-selection").appendChild(option);
  });
  document.getElementById("model-selection").value = selectedModel;

  document.getElementById("download").addEventListener("click", () => {
    initializeWebLLMEngine().then(() => {
      document.getElementById("send").disabled = false;
    });
  });

  document.getElementById("send").addEventListener("click", () => {
    onMessageSend();
  });
</script>
</body>
</html>
