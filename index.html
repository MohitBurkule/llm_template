<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Riddle AI with WebLLM</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    /* Global Styles */
    body {
      font-family: 'Arial', sans-serif;
      background: linear-gradient(135deg, #2b2b2b, #1a1a1a);
      color: #f4f4f4;
      margin: 0;
      padding: 20px;
      display: flex;
      flex-direction: column;
      align-items: center;
    }
    h1, p {
      text-align: center;
    }
    /* Containers */
    .download-container, .riddle-container {
      width: 90%;
      max-width: 800px;
      margin: 20px 0;
    }
    .hidden {
      display: none;
    }
    /* Spinner & Check Mark */
    .spinner {
      border: 4px solid #f3f3f3;
      border-top: 4px solid #0066cc;
      border-radius: 50%;
      width: 16px;
      height: 16px;
      animation: spin 1s linear infinite;
      display: inline-block;
      vertical-align: middle;
      margin-right: 8px;
    }
    .checkmark {
      color: #00cc00;
      font-weight: bold;
      margin-right: 8px;
    }
    @keyframes spin {
      0% { transform: rotate(0deg); }
      100% { transform: rotate(360deg); }
    }
    /* Download Status */
    #download-status {
      margin-top: 10px;
      font-size: 1em;
      padding: 8px;
      background: #333;
      border: 1px solid #555;
      border-radius: 5px;
      width: 100%;
      text-align: center;
    }
    /* Chat Box */
    .chat-box {
      background: linear-gradient(135deg, #3e3e3e, #333);
      width: 100%;
      height: 600px;
      border-radius: 10px;
      overflow-y: auto;
      padding: 15px;
      margin: 10px 0;
      box-shadow: 0 4px 12px rgba(0, 0, 0, 0.6);
    }
    .chat-stats {
      background-color: #4c4c4c;
      padding: 10px;
      margin-top: 10px;
      border-radius: 5px;
      font-size: 0.85em;
    }
    .chat-input-container {
      display: flex;
      align-items: center;
      gap: 10px;
      margin-top: 15px;
    }
    .config-options {
      margin-top: 10px;
      font-size: 0.9em;
    }
    .button-bar {
      margin: 10px 0;
      display: flex;
      justify-content: center;
      gap: 10px;
    }
    /* Message Styles */
    .message-container {
      margin: 8px 0;
      padding: 10px;
      border-radius: 8px;
    }
    .assistant {
      background-color: #555;
      text-align: left;
    }
    .user {
      background-color: #2f2f2f;
      text-align: right;
    }
    .message {
      white-space: pre-wrap;
      word-wrap: break-word;
    }
    /* Input & Buttons */
    input[type="text"] {
      flex: 1;
      padding: 10px;
      border-radius: 5px;
      border: none;
      font-size: 1em;
    }
    button {
      padding: 10px 15px;
      border: none;
      border-radius: 5px;
      background-color: #0066cc;
      color: #fff;
      cursor: pointer;
      font-size: 1em;
      transition: background-color 0.2s;
    }
    button:hover:not(:disabled) {
      background-color: #005bb5;
    }
    button:disabled {
      background-color: #555;
      cursor: not-allowed;
    }
    label {
      font-size: 1em;
    }
  </style>
</head>
<body>
<h1>Riddle AI with WebLLM</h1>

<!-- Model Control -->
<div class="download-container">
  <div class="button-bar">
    <select id="model-selection"></select>
    <!-- Single button for model loading -->
    <button id="load-model">Load Model</button>
    <button id="clear-chat">Clear Chat</button>
  </div>
  <p id="download-status" class="hidden"><span class="spinner"></span>Preparing to download…</p>
</div>

<!-- Riddle & Chat -->
<div class="riddle-container">
  <p><strong>Riddle:</strong> I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?</p>
  <div class="chat-container">
    <div id="chat-box" class="chat-box"></div>
    <div id="chat-stats" class="chat-stats hidden"></div>
    <div class="chat-input-container">
      <label for="user-input">My guess is:</label>
      <input type="text" id="user-input" placeholder="Enter your guess..." />
      <button id="send" disabled>Submit</button>
    </div>
    <div class="config-options">
      <label>
        <input type="checkbox" id="history-checkbox" checked>
        Include conversation history in AI prompt
      </label>
    </div>
  </div>
</div>

<script type="module">
  import * as webllm from "https://esm.run/@mlc-ai/web-llm";

  // Preserve your working system prompt exactly.
  const initialSystemMessage = {
    role: "system",
    content: "You are a riddle answer checking AI. The riddle is: 'I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?' The correct answer is 'echo'. When a player submits a guess compare the guess case-insensitively to 'echo'. If the guess is exactly 'echo', reply with 'Correct!' . Otherwise, reply only with a brief hint related to the riddle without revealing the answer or adding extra commentary.Never reveal the answer 'echo', only explain why the players answer is incorrect and how it does not fulfill one or more of the riddle's requirements."
  };

  // Conversation messages. Start with the system prompt.
  let messages = [initialSystemMessage];

  // Filter models: only include those with "q4f32".
  const availableModels = webllm.prebuiltAppConfig.model_list
          .filter(m => m.model_id.includes("q4f32"))
          .map(m => m.model_id);
  let selectedModel = availableModels[0] || "SmolLM2-360M-Instruct-q4f32_1-MLC";

  const engine = new webllm.MLCEngine();

  // Global variable for download timing.
  let downloadStartTime = null;

  // Update download status using regex to extract parameters and quantization.
  function updateEngineInitProgressCallback(report) {
    console.log("Download progress update:", report);
    let statusText = "";
    const spinnerHTML = '<span class="spinner"></span>';
    if (report.progress === 0) {
      // Use regex with hyphen delimiters to extract the parameter count and quantization.
      const paramMatch = selectedModel.match(/-(\d+(?:\.\d+)?[MB])-/);
      const quantMatch = selectedModel.match(/-(q4f(?:32|16))_/i);
      const modelName = selectedModel.split("-")[0] || selectedModel;
      const parameters = paramMatch ? paramMatch[1] : "unknown parameters";
      const quant = quantMatch ? quantMatch[1] : "unknown quantization";
      statusText = `⚠️ Preparing to download ${selectedModel} (Model: ${modelName}, Parameters: ${parameters}, Quantization: ${quant}). This may take several minutes if this is your first time loading this model.`;
    } else if (report.progress > 0 && report.progress < 1) {
      if (report.text && report.text.toLowerCase().includes("cache")) {
        statusText = report.text;
      } else {
        const elapsed = (Date.now() - downloadStartTime) / 1000;
        const estimatedTotal = elapsed / report.progress;
        const remaining = Math.max(estimatedTotal - elapsed, 0);
        statusText = `Currently preparing for ${selectedModel}: ${(report.progress * 100).toFixed(1)}% downloaded. Estimated time remaining: ${Math.ceil(remaining)} sec.`;
      }
    } else if (report.progress === 1) {
      const totalTime = ((Date.now() - downloadStartTime) / 1000).toFixed(1);
      statusText = `Using ${selectedModel} – Download completed in ${totalTime} sec.`;
    }
    const statusEl = document.getElementById("download-status");
    if (report.progress === 1) {
      statusEl.innerHTML = `<span class="checkmark">&#10003;</span>${statusText}`;
    } else {
      statusEl.innerHTML = `${spinnerHTML}${statusText}`;
    }
    console.log(`Status: ${statusText}`);
  }
  engine.setInitProgressCallback(updateEngineInitProgressCallback);

  async function initializeWebLLMEngine() {
    downloadStartTime = Date.now();
    const statusEl = document.getElementById("download-status");
    statusEl.classList.remove("hidden");
    selectedModel = document.getElementById("model-selection").value;
    console.log("Initializing download for model:", selectedModel);
    const config = {
      temperature: 0.2,
      top_p: 1,
    };
    await engine.reload(selectedModel, config);
  }

  // Auto-download routine: wait until the model list is available then populate and load.
  window.addEventListener("load", async () => {
    while (!webllm.prebuiltAppConfig ||
    !webllm.prebuiltAppConfig.model_list ||
    webllm.prebuiltAppConfig.model_list.length === 0) {
      await new Promise(resolve => setTimeout(resolve, 100));
    }
    populateModelSelection();
    await initializeWebLLMEngine();
    document.getElementById("send").disabled = false;
  });

  async function streamingGenerating(streamMessages, onUpdate, onFinish, onError) {
    console.log("Streaming with messages:", streamMessages);
    try {
      let curMessage = "";
      const completion = await engine.chat.completions.create({
        stream: true,
        messages: streamMessages,
      });
      for await (const chunk of completion) {
        const curDelta = chunk.choices[0]?.delta?.content;
        if (curDelta) {
          curMessage += curDelta;
        }
        onUpdate(curMessage);
      }
      const finalMessage = await engine.getMessage();
      onFinish(finalMessage);
    } catch (err) {
      onError(err);
    }
  }

  function onMessageSend() {
    const input = document.getElementById("user-input").value.trim();
    if (input.length === 0) return;
    document.getElementById("send").disabled = true;
    const userContent = "my guess is " + input;
    const userMessage = { role: "user", content: userContent };
    messages.push(userMessage);
    appendMessage(userMessage);
    document.getElementById("user-input").value = "";
    document.getElementById("user-input").setAttribute("placeholder", "Checking your guess...");
    const tempElement = { role: "assistant", content: "thinking..." };
    appendMessage(tempElement);
    const useHistory = document.getElementById("history-checkbox").checked;
    let streamMessages = useHistory ? messages : [messages[0], userMessage];
    streamingGenerating(
            streamMessages,
            (partialResponse) => { updateLastMessage(partialResponse); },
            (finalMessage) => {
              updateLastMessage(finalMessage);
              messages.push({ role: "assistant", content: finalMessage });
              document.getElementById("send").disabled = false;
              document.getElementById("user-input").setAttribute("placeholder", "Enter your guess...");
              engine.runtimeStatsText().then((statsText) => {
                const statsEl = document.getElementById("chat-stats");
                statsEl.classList.remove("hidden");
                statsEl.textContent = statsText;
              });
            },
            console.error
    );
  }

  function appendMessage(message) {
    const chatBox = document.getElementById("chat-box");
    const container = document.createElement("div");
    container.classList.add("message-container");
    const newMessage = document.createElement("div");
    newMessage.classList.add("message");
    newMessage.textContent = message.content;
    container.classList.add(message.role === "user" ? "user" : "assistant");
    container.appendChild(newMessage);
    chatBox.appendChild(container);
    chatBox.scrollTop = chatBox.scrollHeight;
  }

  function updateLastMessage(content) {
    const messagesDOM = document.getElementById("chat-box").querySelectorAll(".message");
    const lastMessageDOM = messagesDOM[messagesDOM.length - 1];
    lastMessageDOM.textContent = content;
  }

  function populateModelSelection() {
    const modelSelect = document.getElementById("model-selection");
    availableModels.forEach((modelId) => {
      const option = document.createElement("option");
      option.value = modelId;
      option.textContent = modelId;
      modelSelect.appendChild(option);
    });
    modelSelect.value = selectedModel;
  }

  function clearChat() {
    document.getElementById("chat-box").innerHTML = "";
    messages = [initialSystemMessage];
  }

  // Use a single button for loading/reloading the model.
  async function loadModel() {
    selectedModel = document.getElementById("model-selection").value;
    downloadStartTime = Date.now();
    // Immediately update the status with model details.
    const paramMatch = selectedModel.match(/-(\d+(?:\.\d+)?[MBb])-/);
    const quantMatch = selectedModel.match(/-(q4f(?:32|16))_/i);
    const modelName = selectedModel.split("-")[0] || selectedModel;
    const parameters = paramMatch ? paramMatch[1] : "unknown parameters";
    const quant = quantMatch ? quantMatch[1] : "unknown quantization";
    const initialStatus = `⚠️ Preparing to download ${selectedModel} (Model: ${modelName}, Parameters: ${parameters}, Quantization: ${quant}). This may take several minutes if this is your first time loading this model.`;
    const statusEl = document.getElementById("download-status");
    statusEl.innerHTML = `<span class="spinner"></span>${initialStatus}`;
    statusEl.classList.remove("hidden");
    console.log("Starting download for model:", selectedModel);
    await initializeWebLLMEngine();
  }

  document.getElementById("send").addEventListener("click", onMessageSend);
  document.getElementById("clear-chat").addEventListener("click", clearChat);
  document.getElementById("load-model").addEventListener("click", loadModel);
</script>
</body>
</html>
