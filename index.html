<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Riddle AI with WebLLM</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      font-family: 'Arial', sans-serif;
      background-color: #2b2b2b;
      color: #f4f4f4;
      margin: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 10px;
    }
    h1, p {
      text-align: center;
    }
    .download-container, .riddle-container {
      margin: 20px 0;
    }
    .hidden {
      display: none;
    }
    .chat-box {
      background-color: #3e3e3e;
      width: 90%;
      max-width: 600px;
      height: 150px;
      border-radius: 10px;
      overflow-y: auto;
      padding: 10px;
      margin: 10px 0;
    }
    .chat-stats {
      background-color: #4c4c4c;
      padding: 10px;
      margin-top: 10px;
      border-radius: 5px;
    }
    .chat-input-container {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-top: 10px;
    }
    .message-container {
      margin: 5px 0;
      padding: 8px;
      border-radius: 5px;
    }
    .assistant {
      background-color: #444;
      text-align: left;
    }
    .user {
      background-color: #2f2f2f;
      text-align: right;
    }
    .message {
      white-space: pre-wrap;
      word-wrap: break-word;
    }
  </style>
</head>

<body>
<h1>Riddle AI with WebLLM</h1>

<!-- Step 1: Model Initialization -->
<p>Select a model and download it before answering the riddle:</p>
<div class="download-container">
  <select id="model-selection"></select>
  <button id="download">Download</button>
  <p id="download-status" class="hidden"></p>
</div>

<!-- Step 2: Riddle Game -->
<div class="riddle-container">
  <p><strong>Riddle:</strong> I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?</p>
  <div class="chat-container">
    <div id="chat-box" class="chat-box"></div>
    <div id="chat-stats" class="chat-stats hidden"></div>
    <div class="chat-input-container">
      <input
              type="text"
              id="user-input"
              placeholder="Enter your guess..."
      />
      <button id="send" disabled>Submit</button>
    </div>
  </div>
</div>

<script type="module">
  /*************** WebLLM logic ***************/
  import * as webllm from "https://esm.run/@mlc-ai/web-llm";

  // Revised system prompt with explicit instructions and the correct answer.
  const messages = [
    {
      content: "You are a riddle-checking AI. The riddle is: 'I speak without a mouth and hear without ears. I have no body, but I come alive with wind.' The correct answer is 'echo'. When a player submits a guess, if the guess (ignoring case) is 'echo', reply with 'Correct!'. Otherwise, provide a hint related to the riddle without revealing the answer, and ask the player to try again. Do not provide a new riddle.",
      role: "system",
    },
  ];

  // Filter models to only include those with "q4f32" in their name.
  const availableModels = webllm.prebuiltAppConfig.model_list
          .filter(m => m.model_id.includes("q4f32"))
          .map(m => m.model_id);
  let selectedModel = availableModels[0] || "TinyLlama-1.1B-Chat-v1.0-q4f32_1-MLC-1k";

  // Create an engine instance
  const engine = new webllm.MLCEngine();

  // Show model download progress
  function updateEngineInitProgressCallback(report) {
    console.log("initialize", report.progress);
    document.getElementById("download-status").textContent = report.text;
  }
  engine.setInitProgressCallback(updateEngineInitProgressCallback);

  // Download / reload the model
  async function initializeWebLLMEngine() {
    document.getElementById("download-status").classList.remove("hidden");
    selectedModel = document.getElementById("model-selection").value;
    const config = {
      temperature: 1.0,
      top_p: 1,
    };
    await engine.reload(selectedModel, config);
  }

  // Utility for streaming generation
  async function streamingGenerating(messages, onUpdate, onFinish, onError) {
    try {
      let curMessage = "";
      const completion = await engine.chat.completions.create({
        stream: true,
        messages,
      });
      for await (const chunk of completion) {
        const curDelta = chunk.choices[0]?.delta?.content;
        if (curDelta) {
          curMessage += curDelta;
        }
        onUpdate(curMessage);
      }
      const finalMessage = await engine.getMessage();
      onFinish(finalMessage);
    } catch (err) {
      onError(err);
    }
  }

  /*************** UI logic ***************/
  // Called when user submits a guess
  function onMessageSend() {
    const input = document.getElementById("user-input").value.trim();
    const message = {
      content: input,
      role: "user",
    };
    if (input.length === 0) return;

    // Lock the UI
    document.getElementById("send").disabled = true;

    messages.push(message);
    appendMessage(message);

    // Clear and disable input
    document.getElementById("user-input").value = "";
    document
            .getElementById("user-input")
            .setAttribute("placeholder", "Checking your guess...");

    // Stub for the AI's message
    const aiMessage = {
      content: "thinking...",
      role: "assistant",
    };
    appendMessage(aiMessage);

    // This function will handle finalizing
    const onFinishGenerating = (finalMessage) => {
      updateLastMessage(finalMessage);
      document.getElementById("send").disabled = false;
      document
              .getElementById("user-input")
              .setAttribute("placeholder", "Enter your guess...");

      // Show runtime stats
      engine.runtimeStatsText().then((statsText) => {
        document.getElementById("chat-stats").classList.remove("hidden");
        document.getElementById("chat-stats").textContent = statsText;
      });
    };

    // Stream the generation
    streamingGenerating(messages, updateLastMessage, onFinishGenerating, console.error);
  }

  // Append a new bubble to the chat box
  function appendMessage(message) {
    const chatBox = document.getElementById("chat-box");
    const container = document.createElement("div");
    container.classList.add("message-container");
    const newMessage = document.createElement("div");
    newMessage.classList.add("message");
    newMessage.textContent = message.content;

    if (message.role === "user") {
      container.classList.add("user");
    } else {
      container.classList.add("assistant");
    }
    container.appendChild(newMessage);
    chatBox.appendChild(container);
    chatBox.scrollTop = chatBox.scrollHeight;
  }

  // Update the most recent bubble's text (AI's bubble in this case)
  function updateLastMessage(content) {
    const messageDoms = document
            .getElementById("chat-box")
            .querySelectorAll(".message");
    const lastMessageDom = messageDoms[messageDoms.length - 1];
    lastMessageDom.textContent = content;
  }

  // Populate model dropdown with filtered models
  availableModels.forEach((modelId) => {
    const option = document.createElement("option");
    option.value = modelId;
    option.textContent = modelId;
    document.getElementById("model-selection").appendChild(option);
  });
  document.getElementById("model-selection").value = selectedModel;

  // Bind the download button
  document.getElementById("download").addEventListener("click", () => {
    initializeWebLLMEngine().then(() => {
      // Enable the Submit button after model is loaded
      document.getElementById("send").disabled = false;
    });
  });

  // Bind the send button (submit guess)
  document.getElementById("send").addEventListener("click", () => {
    onMessageSend();
  });
</script>
</body>
</html>
