<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Riddle AI with WebLLM</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      font-family: 'Arial', sans-serif;
      background-color: #2b2b2b;
      color: #f4f4f4;
      margin: 0;
      display: flex;
      flex-direction: column;
      align-items: center;
      padding: 10px;
    }
    h1, p {
      text-align: center;
    }
    .download-container, .riddle-container {
      margin: 20px 0;
    }
    .hidden {
      display: none;
    }
    .chat-box {
      background-color: #3e3e3e;
      width: 90%;
      max-width: 600px;
      height: 150px;
      border-radius: 10px;
      overflow-y: auto;
      padding: 10px;
      margin: 10px 0;
    }
    .chat-stats {
      background-color: #4c4c4c;
      padding: 10px;
      margin-top: 10px;
      border-radius: 5px;
    }
    .chat-input-container {
      display: flex;
      justify-content: center;
      gap: 10px;
      margin-top: 10px;
    }
    .message-container {
      margin: 5px 0;
      padding: 8px;
      border-radius: 5px;
    }
    .assistant {
      background-color: #444;
      text-align: left;
    }
    .user {
      background-color: #2f2f2f;
      text-align: right;
    }
    .message {
      white-space: pre-wrap;
      word-wrap: break-word;
    }
  </style>
</head>

<body>
<h1>Riddle AI with WebLLM</h1>

<!-- Step 1: Model Initialization -->
<p>Select a model and download it before answering the riddle:</p>
<div class="download-container">
  <select id="model-selection"></select>
  <button id="download">Download</button>
  <p id="download-status" class="hidden"></p>
</div>

<!-- Step 2: Riddle Game -->
<div class="riddle-container">
  <p><strong>Riddle:</strong> I speak without a mouth and hear without ears. I have no body, but I come alive with wind. What am I?</p>
  <div class="chat-container">
    <div id="chat-box" class="chat-box"></div>
    <div id="chat-stats" class="chat-stats hidden"></div>
    <div class="chat-input-container">
      <input type="text" id="user-input" placeholder="Enter your guess..." />
      <button id="send" disabled>Submit</button>
    </div>
  </div>
</div>

<script type="module">
  /*************** WebLLM logic ***************/
  import * as webllm from "https://esm.run/@mlc-ai/web-llm";

  // Updated conversation context:
  // The system prompt now includes explicit instructions with several examples.
  // Additional messages follow as examples to further illustrate expected responses.
const messages = [
  {
    role: "system",
    content: "You are a riddle-checking AI. The riddle is: 'I speak without a mouth and hear without ears. I have no body, but I come alive with wind.' The correct answer is 'echo'. When a player submits a guess, check it against 'echo'. If the guess is exactly 'echo', reply with 'Correct!' and nothing else. If the guess is anything else, reply only with a short hint related to the riddle.Never give the player the actual answer. Do not generate any additional creative or extraneous text."
  },
  // {
  //   role: "user",
  //   content: "You are a riddle-checking AI. The riddle is: 'I speak without a mouth and hear without ears. I have no body, but I come alive with wind.' The correct answer is 'echo'. When a player submits a guess, check it case-insensitively against 'echo'. If the guess is exactly 'echo', reply with 'Correct!' and nothing else. If the guess is anything else, reply only with a short hint related to the riddle. Do not generate any additional creative or extraneous text.Assume that all the next user responses are from the player"
  // },
  // {
  //   role: "assistant",
  //   content: "Sure thing! Let's start the game. What is your guess?"
  // },
  // {
  //   role: "user",
  //   content: "sound"
  // },
  // {
  //   role: "assistant",
  //   content: "That is also the wrong answer, its  close, but consider a phenomenon that reflects your words."
  // },
  // {
  //   role: "user",
  //   content: "echo"
  // },
  // {
  //   role: "assistant",
  //   content: "That is the correct answer"
  // },
  // {
  //   role: "system",
  //   content: "Lets try that again. You are a riddle-checking AI. The riddle is: 'I speak without a mouth and hear without ears. I have no body, but I come alive with wind.' The correct answer is 'echo'. When a player submits a guess, check it case-insensitively against 'echo'. If the guess is exactly 'echo', reply with 'Correct!' and nothing else. If the guess is anything else, reply only with a short hint related to the riddle. Do not generate any additional creative or extraneous text."
  // },

];


  // Filter models to only include those with "q4f32" in their name.
  const availableModels = webllm.prebuiltAppConfig.model_list
          .filter(m => m.model_id.includes("q4f32"))
          .filter(m => m.model_id.includes("SmolLM2"))
          .map(m => m.model_id);
  let selectedModel = availableModels[0] || "SmolLM2-360M-Instruct-q4f32_1-MLC";

  // Create an engine instance.
  const engine = new webllm.MLCEngine();

  // Show model download progress.
  function updateEngineInitProgressCallback(report) {
    console.log("initialize", report.progress);
    document.getElementById("download-status").textContent = report.text;
  }
  engine.setInitProgressCallback(updateEngineInitProgressCallback);

  // Download / reload the model.
  async function initializeWebLLMEngine() {
    document.getElementById("download-status").classList.remove("hidden");
    selectedModel = document.getElementById("model-selection").value;
    const config = {
      temperature: 0.2, // Lower temperature reduces creative output.
      top_p: 1,
    };
    await engine.reload(selectedModel, config);
  }

  // Utility for streaming generation.
  async function streamingGenerating(messages, onUpdate, onFinish, onError) {
    console.log(messages)
    try {
      let curMessage = "";
      const completion = await engine.chat.completions.create({
        stream: true,
        messages,
      });
      for await (const chunk of completion) {
        const curDelta = chunk.choices[0]?.delta?.content;
        if (curDelta) {
          curMessage += curDelta;
        }
        onUpdate(curMessage);
      }
      const finalMessage = await engine.getMessage();
      onFinish(finalMessage);
    } catch (err) {
      onError(err);
    }
  }

  /*************** UI logic ***************/
// Called when user submits a guess.
  // Called when user submits a guess.
  function onMessageSend() {
    const input = document.getElementById("user-input").value.trim();
    if (input.length === 0) return;

    // Disable the UI.
    document.getElementById("send").disabled = true;

    // Append the user's message to the conversation.
    const userMessage = { role: "user", content: input };
    messages.push(userMessage);
    appendMessage(userMessage);

    // Clear input and set placeholder.
    document.getElementById("user-input").value = "";
    document.getElementById("user-input").setAttribute("placeholder", "Checking your guess...");

    // Add a temporary "thinking..." message only to the UI.
    const tempElement = { role: "assistant", content: "thinking..." };
    appendMessage(tempElement);

    // IMPORTANT: Do NOT push the temporary assistant message to the messages array.
    // The messages array must end with a user message when calling streamingGenerating.

    // Call streaming generation with the current messages array (which ends with a user message).
    streamingGenerating(
            messages,
            // onUpdate: update the last assistant bubble in the UI.
            (partialResponse) => {
              updateLastMessage(partialResponse);
            },
            // onFinish: once final response is generated, update the UI and conversation array.
            (finalMessage) => {
              // Remove the temporary assistant bubble from the UI if needed, or simply update it.
              updateLastMessage(finalMessage);
              // Now append the final assistant message to the messages array.
              messages.push({ role: "assistant", content: finalMessage });
              document.getElementById("send").disabled = false;
              document.getElementById("user-input").setAttribute("placeholder", "Enter your guess...");

              // Optionally, show runtime stats.
              engine.runtimeStatsText().then((statsText) => {
                document.getElementById("chat-stats").classList.remove("hidden");
                document.getElementById("chat-stats").textContent = statsText;
              });
            },
            console.error
    );
  }


  // Append a new bubble to the chat box.
  function appendMessage(message) {
    const chatBox = document.getElementById("chat-box");
    const container = document.createElement("div");
    container.classList.add("message-container");
    const newMessage = document.createElement("div");
    newMessage.classList.add("message");
    newMessage.textContent = message.content;

    if (message.role === "user") {
      container.classList.add("user");
    } else {
      container.classList.add("assistant");
    }
    container.appendChild(newMessage);
    chatBox.appendChild(container);
    chatBox.scrollTop = chatBox.scrollHeight;
  }

  // Update the most recent bubble's text (AI's bubble).
  function updateLastMessage(content) {
    const messageDoms = document.getElementById("chat-box").querySelectorAll(".message");
    const lastMessageDom = messageDoms[messageDoms.length - 1];
    lastMessageDom.textContent = content;
  }

  // Populate model dropdown with filtered models.
  availableModels.forEach((modelId) => {
    const option = document.createElement("option");
    option.value = modelId;
    option.textContent = modelId;
    document.getElementById("model-selection").appendChild(option);
  });
  document.getElementById("model-selection").value = selectedModel;

  // Bind the download button.
  document.getElementById("download").addEventListener("click", () => {
    initializeWebLLMEngine().then(() => {
      // Enable the Submit button after model is loaded.
      document.getElementById("send").disabled = false;
    });
  });

  // Bind the send button (submit guess).
  document.getElementById("send").addEventListener("click", () => {
    onMessageSend();
  });
</script>
</body>
</html>
